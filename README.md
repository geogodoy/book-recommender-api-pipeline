# Book Recommender API Pipeline

**Tech Challenge - PÃ³s-Tech | Fase 1 - Machine Learning Engineering**

Uma API RESTful completa para consulta de livros, desenvolvida como parte do Tech Challenge da primeira fase do curso de Machine Learning Engineering.

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um pipeline completo de dados e uma API pÃºblica para servir informaÃ§Ãµes de livros extraÃ­das via web scraping do site [Books to Scrape](https://books.toscrape.com/). A soluÃ§Ã£o foi projetada pensando em escalabilidade e reusabilidade futura em modelos de machine learning.

## ğŸ—ï¸ Arquitetura

```
book-recommender-api-pipeline/
â”œâ”€â”€ data/                    # Dados armazenados (CSV e SQLite)
â”œâ”€â”€ scripts/                 # Scripts de scraping e ETL
â”‚   â”œâ”€â”€ scrape_books.py     # Web scraper principal
â”‚   â””â”€â”€ csv_to_db.py        # Pipeline CSV â†’ Database
â”œâ”€â”€ api/                    # MÃ³dulos da API
â”‚   â”œâ”€â”€ database.py         # ConfiguraÃ§Ã£o do banco de dados
â”‚   â”œâ”€â”€ models.py           # Modelos SQLAlchemy
â”‚   â”œâ”€â”€ schemas.py          # Schemas Pydantic
â”‚   â””â”€â”€ crud.py             # OperaÃ§Ãµes CRUD
â”œâ”€â”€ main.py                 # AplicaÃ§Ã£o FastAPI principal
â”œâ”€â”€ setup.py                # Script de configuraÃ§Ã£o inicial
â”œâ”€â”€ run_api.py              # Script para executar a API
â”œâ”€â”€ test_api.py             # Script de testes da API
â””â”€â”€ requirements.txt        # DependÃªncias do projeto
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- pip

### Setup AutomÃ¡tico
Execute o script de configuraÃ§Ã£o que irÃ¡ instalar dependÃªncias, fazer scraping e configurar o banco:

```bash
python setup.py
```

### Setup Manual

1. **Clone o repositÃ³rio e instale dependÃªncias:**
```bash
git clone <repository-url>
cd book-recommender-api-pipeline
pip install -r requirements.txt
```

2. **Execute o web scraping:**
```bash
python scripts/scrape_books.py
```

3. **Carregue os dados no banco:**
```bash
python scripts/csv_to_db.py
```

## ğŸ¯ Executando a API

### MÃ©todo 1: Script de execuÃ§Ã£o
```bash
python run_api.py
```

### MÃ©todo 2: Comando direto
```bash
python main.py
```

A API estarÃ¡ disponÃ­vel em: `http://localhost:8000`

## ğŸ“š DocumentaÃ§Ã£o da API

### URLs Importantes
- **DocumentaÃ§Ã£o Swagger:** `http://localhost:8000/docs`
- **DocumentaÃ§Ã£o ReDoc:** `http://localhost:8000/redoc`
- **Health Check:** `http://localhost:8000/api/v1/health`

### Endpoints Core

#### `GET /api/v1/books`
Lista todos os livros disponÃ­veis na base de dados.

**ParÃ¢metros:**
- `skip` (int): NÃºmero de livros a pular (paginaÃ§Ã£o)
- `limit` (int): NÃºmero de livros a retornar (mÃ¡x: 1000)

**Exemplo:**
```bash
curl "http://localhost:8000/api/v1/books?limit=5"
```

#### `GET /api/v1/books/{id}`
Retorna detalhes completos de um livro especÃ­fico pelo ID.

**Exemplo:**
```bash
curl "http://localhost:8000/api/v1/books/1"
```

#### `GET /api/v1/books/search`
Busca livros por tÃ­tulo e/ou categoria.

**ParÃ¢metros:**
- `title` (str): Busca por tÃ­tulo (parcial)
- `category` (str): Busca por categoria

**Exemplo:**
```bash
curl "http://localhost:8000/api/v1/books/search?title=python&category=programming"
```

#### `GET /api/v1/categories`
Lista todas as categorias de livros disponÃ­veis.

**Exemplo:**
```bash
curl "http://localhost:8000/api/v1/categories"
```

#### `GET /api/v1/health`
Verifica status da API e conectividade com os dados.

**Exemplo:**
```bash
curl "http://localhost:8000/api/v1/health"
```

### Endpoints de Insights

#### `GET /api/v1/stats/overview`
EstatÃ­sticas gerais da coleÃ§Ã£o (total de livros, preÃ§o mÃ©dio, distribuiÃ§Ã£o de ratings).

#### `GET /api/v1/stats/categories`
EstatÃ­sticas detalhadas por categoria (quantidade de livros, preÃ§os por categoria).

#### `GET /api/v1/books/top-rated`
Lista os livros com melhor avaliaÃ§Ã£o (rating mais alto).

#### `GET /api/v1/books/price-range`
Filtra livros dentro de uma faixa de preÃ§o especÃ­fica.

**ParÃ¢metros:**
- `min_price` (float): PreÃ§o mÃ­nimo
- `max_price` (float): PreÃ§o mÃ¡ximo

## ğŸ§ª Testando a API

Execute o script de testes para verificar todos os endpoints:

```bash
python test_api.py
```

## ğŸ“Š Dados ExtraÃ­dos

O web scraper coleta os seguintes campos de cada livro:

- **TÃ­tulo:** Nome completo do livro
- **PreÃ§o:** Valor em libras (convertido para float)
- **AvaliaÃ§Ã£o:** Rating de 1 a 5 estrelas (One, Two, Three, Four, Five)
- **Disponibilidade:** Status de estoque
- **Categoria:** GÃªnero/categoria do livro
- **Imagem:** URL da capa do livro
- **Link:** URL da pÃ¡gina do livro

## ğŸ”§ Estrutura do Banco de Dados

O projeto utiliza SQLite como banco local com a seguinte estrutura:

```sql
CREATE TABLE books (
    id INTEGER PRIMARY KEY,
    title VARCHAR NOT NULL,
    price FLOAT,
    rating VARCHAR,
    availability VARCHAR,
    category VARCHAR,
    image_url TEXT,
    link TEXT
);
```

## ğŸš€ Pipeline de Dados

1. **ExtraÃ§Ã£o:** Web scraping do site Books to Scrape
2. **TransformaÃ§Ã£o:** Limpeza e normalizaÃ§Ã£o dos dados
3. **Armazenamento:** Salvamento em CSV e carregamento no SQLite
4. **DisponibilizaÃ§Ã£o:** API RESTful para consulta dos dados

## ğŸ¯ CenÃ¡rios de Uso para ML

Esta API foi projetada para facilitar o desenvolvimento de sistemas de recomendaÃ§Ã£o:

- **Features CategÃ³ricas:** Categoria, rating, disponibilidade
- **Features NumÃ©ricas:** PreÃ§o, ID
- **Features Textuais:** TÃ­tulo (para NLP)
- **Metadata:** URLs de imagens e links

## ğŸ“ˆ PrÃ³ximos Passos

- [ ] ImplementaÃ§Ã£o de autenticaÃ§Ã£o JWT
- [ ] Endpoints especÃ­ficos para ML (features, training data)
- [ ] Sistema de monitoramento e analytics
- [ ] Deploy em produÃ§Ã£o (Heroku/Render)
- [ ] Cache Redis para performance
- [ ] Testes automatizados

## ğŸ› ï¸ Tecnologias Utilizadas

- **Python 3.8+**
- **FastAPI** - Framework web assÃ­ncrono
- **SQLAlchemy** - ORM para banco de dados
- **SQLite** - Banco de dados local
- **Pandas** - ManipulaÃ§Ã£o de dados
- **BeautifulSoup4** - Web scraping
- **Requests** - RequisiÃ§Ãµes HTTP
- **Pydantic** - ValidaÃ§Ã£o de dados
- **Uvicorn** - Servidor ASGI

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido para fins educacionais como parte do Tech Challenge da PÃ³s-Tech.

---

**Desenvolvido por:** [Seu Nome]  
**Curso:** PÃ³s-Tech | Machine Learning Engineering - Fase 1  
**Data:** 2024