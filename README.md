# Book Recommender API Pipeline

**Tech Challenge - PÃ³s-Tech | Fase 1 - Machine Learning Engineering**

Uma API RESTful completa para consulta de livros com pipeline de dados automatizado, desenvolvida como parte do Tech Challenge da primeira fase do curso de Machine Learning Engineering.

## ğŸ“‹ DescriÃ§Ã£o do Projeto

Este projeto implementa um **pipeline completo de dados** e uma **API RESTful robusta** para servir informaÃ§Ãµes de livros extraÃ­das via web scraping do site [Books to Scrape](https://books.toscrape.com/). 

### ğŸ¯ Objetivos
- **ExtraÃ§Ã£o automatizada** de dados de livros via web scraping
- **API RESTful** performÃ¡tica com documentaÃ§Ã£o interativa
- **Pipeline ETL** completo (ExtraÃ§Ã£o â†’ TransformaÃ§Ã£o â†’ Carregamento)
- **Arquitetura escalÃ¡vel** para integraÃ§Ã£o futura com modelos de ML
- **ContainerizaÃ§Ã£o** com Docker para deploy simplificado

### ğŸ”§ CaracterÃ­sticas TÃ©cnicas
- **Framework:** FastAPI com documentaÃ§Ã£o automÃ¡tica (Swagger/ReDoc)
- **Banco de Dados:** SQLite com SQLAlchemy ORM
- **ValidaÃ§Ã£o:** Pydantic para schemas de request/response
- **Performance:** Endpoints otimizados com indexaÃ§Ã£o de banco
- **Observabilidade:** Health checks e endpoints de status

## ğŸ—ï¸ Arquitetura do Sistema

```
book-recommender-api-pipeline/
â”œâ”€â”€ ğŸ“ data/                    # Camada de Dados
â”‚   â”œâ”€â”€ books.csv              # Dados extraÃ­dos (formato raw)
â”‚   â””â”€â”€ books.db               # Base de dados SQLite (formato estruturado)
â”œâ”€â”€ ğŸ“ scripts/                 # Pipeline ETL
â”‚   â”œâ”€â”€ scrape_books.py        # Extrator: Web scraping automatizado
â”‚   â””â”€â”€ csv_to_db.py           # Carregador: CSV â†’ Database
â”œâ”€â”€ ğŸ“ api/                     # Camada de AplicaÃ§Ã£o
â”‚   â”œâ”€â”€ database.py            # ConfiguraÃ§Ã£o do ORM e modelos
â”‚   â”œâ”€â”€ models.py              # Modelos de dados (SQLAlchemy)
â”‚   â”œâ”€â”€ schemas.py             # Schemas de validaÃ§Ã£o (Pydantic)
â”‚   â””â”€â”€ crud.py                # OperaÃ§Ãµes de banco (CRUD)
â”œâ”€â”€ ğŸ“„ main.py                  # AplicaÃ§Ã£o FastAPI principal
â”œâ”€â”€ ğŸ“„ setup.py                 # AutomaÃ§Ã£o de setup inicial
â”œâ”€â”€ ğŸ“„ requirements.txt         # DependÃªncias do projeto
â”œâ”€â”€ ğŸ“„ Dockerfile              # ContainerizaÃ§Ã£o
â””â”€â”€ ğŸ“„ docker-compose.yml      # OrquestraÃ§Ã£o de containers
```

### ğŸ”„ Fluxo de Dados
```
[Books to Scrape] â†’ [Web Scraper] â†’ [CSV] â†’ [ETL Pipeline] â†’ [SQLite] â†’ [FastAPI] â†’ [Cliente]
```

> ğŸ“Š **DocumentaÃ§Ã£o Detalhada:** Para uma anÃ¡lise completa do pipeline com diagramas interativos, mÃ©tricas de performance e arquitetura detalhada, consulte [PIPELINE.md](./PIPELINE.md)

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### ğŸ“‹ PrÃ©-requisitos
- **Python 3.8+** (recomendado: 3.9 ou superior)
- **pip** (gerenciador de pacotes Python)
- **Git** (para clonagem do repositÃ³rio)
- **4GB RAM** mÃ­nimo para processamento dos dados
- **ConexÃ£o com internet** para web scraping inicial

### âš¡ Setup AutomÃ¡tico (Recomendado)

O projeto inclui um script de setup totalmente automatizado que:
- âœ… Cria ambiente virtual Python
- âœ… Instala todas as dependÃªncias
- âœ… Executa web scraping (se necessÃ¡rio)
- âœ… Configura o banco de dados SQLite
- âœ… Valida a instalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd book-recommender-api-pipeline

# Execute o setup automÃ¡tico
python setup.py
```

**SaÃ­da esperada:**
```
ğŸš€ Setting up Book Recommender API...
==================================================
ğŸ Creating Python virtual environment...
âœ… Virtual environment created successfully!
ğŸ“¦ Installing required dependencies...
âœ… Dependencies installed successfully!
ğŸ“„ No existing data found, running scraper...
ğŸ•·ï¸  Running web scraper...
âœ… Scraping completed!
ğŸ—ƒï¸  Setting up database...
âœ… Database setup completed!
==================================================
âœ… Setup completed successfully!
```

### ğŸ”§ Setup Manual (AvanÃ§ado)

Para maior controle do processo de instalaÃ§Ã£o:

#### 1. **PreparaÃ§Ã£o do Ambiente**
```bash
# Clone o repositÃ³rio
git clone <repository-url>
cd book-recommender-api-pipeline

# Crie ambiente virtual (recomendado)
python -m venv venv

# Ative o ambiente virtual
# Linux/Mac:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# Instale dependÃªncias
pip install -r requirements.txt
```

#### 2. **ExtraÃ§Ã£o de Dados (Web Scraping)**
```bash
# Execute o scraper para obter dados atualizados
python scripts/scrape_books.py

# Verificar dados extraÃ­dos
ls -la data/books.csv
```

#### 3. **ConfiguraÃ§Ã£o do Banco de Dados**
```bash
# Carregue dados CSV para SQLite
python scripts/csv_to_db.py

# Verificar banco criado
ls -la data/books.db
```

#### 4. **ValidaÃ§Ã£o da InstalaÃ§Ã£o**
```bash
# Teste rÃ¡pido da API
python -c "
from api.database import get_db, Book
from sqlalchemy.orm import Session
next(get_db()).query(Book).count()
print('âœ… Database OK!')
"
```

### ğŸ³ InstalaÃ§Ã£o com Docker (Opcional)

Para ambiente completamente isolado:

```bash
# Build da imagem
docker build -t book-recommender-api .

# ExecuÃ§Ã£o do container
docker run -p 8000:8000 book-recommender-api

# Ou usando docker-compose
docker-compose up --build
```

### ğŸ“¦ DependÃªncias do Projeto

```txt
requests==2.32.3        # RequisiÃ§Ãµes HTTP para scraping
beautifulsoup4==4.12.3  # Parsing HTML
pandas==2.2.2           # ManipulaÃ§Ã£o de dados
fastapi==0.116.0        # Framework web
uvicorn[standard]==0.35.0  # Servidor ASGI
python-dotenv==1.1.1    # VariÃ¡veis de ambiente
sqlalchemy==2.0.36      # ORM de banco de dados
gunicorn==21.2.0        # Servidor WSGI para produÃ§Ã£o
psutil==5.9.8           # InformaÃ§Ãµes do sistema
```

### ğŸ” VerificaÃ§Ã£o de Problemas Comuns

**Erro de permissÃ£o no Python:**
```bash
# Use o flag --user se nÃ£o tiver privilÃ©gios admin
pip install --user -r requirements.txt
```

**Erro no web scraping:**
```bash
# Verifique conectividade
curl -I https://books.toscrape.com/
# Se OK, execute novamente o scraper
python scripts/scrape_books.py
```

**Banco de dados nÃ£o criado:**
```bash
# Verifique se o diretÃ³rio data/ existe
mkdir -p data
# Execute novamente o carregamento
python scripts/csv_to_db.py
```

## ğŸ¯ Executando a API

### ğŸš€ MÃ©todos de ExecuÃ§Ã£o

#### **MÃ©todo 1: Script de ExecuÃ§Ã£o (Recomendado)**
```bash
# Execute o script otimizado
python run_api.py
```

#### **MÃ©todo 2: Comando Direto**
```bash
# ExecuÃ§Ã£o direta da aplicaÃ§Ã£o
python main.py
```

#### **MÃ©todo 3: Uvicorn Manual**
```bash
# ExecuÃ§Ã£o com controle total dos parÃ¢metros
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

#### **MÃ©todo 4: Com Ambiente Virtual**
```bash
# Ative o ambiente virtual primeiro
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# Execute a API
python main.py
```

#### **MÃ©todo 5: ProduÃ§Ã£o com Gunicorn**
```bash
# Para ambiente de produÃ§Ã£o
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

#### **MÃ©todo 6: Docker**
```bash
# Usando Docker
docker run -p 8000:8000 book-recommender-api

# Ou com Docker Compose
docker-compose up
```

### ğŸ“ URLs de Acesso

ApÃ³s iniciar a API, acesse:

| ServiÃ§o | URL | DescriÃ§Ã£o |
|---------|-----|-----------|
| **API Principal** | `http://localhost:8000` | Endpoint raiz |
| **DocumentaÃ§Ã£o Swagger** | `http://localhost:8000/docs` | Interface interativa da API |
| **DocumentaÃ§Ã£o ReDoc** | `http://localhost:8000/redoc` | DocumentaÃ§Ã£o alternativa |
| **Health Check** | `http://localhost:8000/api/v1/health` | Status da API |
| **Status RÃ¡pido** | `http://localhost:8000/api/v1/status` | VerificaÃ§Ã£o bÃ¡sica |

### ğŸ”§ ConfiguraÃ§Ã£o de Ambiente

#### **VariÃ¡veis de Ambiente Suportadas**
```bash
# Porta da aplicaÃ§Ã£o (padrÃ£o: 8000)
export PORT=8000

# URL do banco de dados (padrÃ£o: sqlite:///./data/books.db)
export DATABASE_URL="sqlite:///./data/books.db"

# Ambiente de execuÃ§Ã£o
export ENVIRONMENT="development"  # ou "production"
```

#### **Arquivo .env (Opcional)**
```bash
# Crie um arquivo .env na raiz do projeto
PORT=8000
DATABASE_URL=sqlite:///./data/books.db
ENVIRONMENT=development
```

### ğŸ“Š Monitoramento da ExecuÃ§Ã£o

#### **VerificaÃ§Ã£o RÃ¡pida**
```bash
# Teste se a API estÃ¡ respondendo
curl http://localhost:8000/api/v1/status

# Resposta esperada:
# {"status": "ok", "message": "API is running"}
```

#### **Health Check Completo**
```bash
# VerificaÃ§Ã£o completa com status do banco
curl http://localhost:8000/api/v1/health

# Resposta esperada:
# {
#   "status": "healthy",
#   "database_connected": true,
#   "total_books": 1
# }
```

#### **Logs da AplicaÃ§Ã£o**
```bash
# Para ver logs detalhados durante execuÃ§Ã£o
python main.py --log-level debug

# Ou usando uvicorn
uvicorn main:app --log-level debug
```

### âš¡ Performance e OtimizaÃ§Ã£o

#### **ConfiguraÃ§Ã£o para Desenvolvimento**
```bash
# Modo desenvolvimento com auto-reload
uvicorn main:app --reload --log-level info
```

#### **ConfiguraÃ§Ã£o para ProduÃ§Ã£o**
```bash
# MÃºltiplos workers para melhor performance
gunicorn main:app \
  -w 4 \
  -k uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --access-logfile logs/access.log \
  --error-logfile logs/error.log
```

### ğŸ›‘ Parar a API

```bash
# Se executando em primeiro plano: Ctrl+C

# Se executando em background:
# Encontre o processo
ps aux | grep "python main.py"

# Mate o processo (substitua PID pelo nÃºmero encontrado)
kill <PID>

# Ou force kill se necessÃ¡rio
kill -9 <PID>
```

## ğŸ“š DocumentaÃ§Ã£o Completa da API

### ğŸŒ URLs Importantes
| Recurso | URL | DescriÃ§Ã£o |
|---------|-----|-----------|
| **API Principal** | `http://localhost:8000` | Endpoint raiz |
| **DocumentaÃ§Ã£o Swagger** | `http://localhost:8000/docs` | Interface interativa (recomendado) |
| **DocumentaÃ§Ã£o ReDoc** | `http://localhost:8000/redoc` | DocumentaÃ§Ã£o alternativa |
| **Health Check** | `http://localhost:8000/api/v1/health` | Status da API |

### ğŸ“‹ Schemas de Dados

#### **Schema do Livro (Book)**
```json
{
  "id": 1,
  "title": "A Light in the Attic",
  "price": 51.77,
  "rating": "Three",
  "availability": "In stock",
  "category": "Poetry",
  "image_url": "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg",
  "link": "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
}
```

#### **Schema de Health Check**
```json
{
  "status": "healthy",
  "database_connected": true,
  "total_books": 1000
}
```

#### **Schema de EstatÃ­sticas Gerais**
```json
{
  "total_books": 1000,
  "average_price": 35.67,
  "rating_distribution": {
    "One": 50,
    "Two": 100,
    "Three": 200,
    "Four": 350,
    "Five": 300
  },
  "categories_count": 50
}
```

#### **Schema de EstatÃ­sticas por Categoria**
```json
{
  "category": "Poetry",
  "book_count": 19,
  "average_price": 42.35,
  "min_price": 13.99,
  "max_price": 57.25
}
```

### ğŸ”— Endpoints Principais

#### **ğŸ“– Listar Livros**
```http
GET /api/v1/books
```

**ParÃ¢metros de Query:**
- `skip` (int, opcional): NÃºmero de livros a pular (padrÃ£o: 0)
- `limit` (int, opcional): NÃºmero de livros a retornar (padrÃ£o: 100, mÃ¡x: 1000)

**ValidaÃ§Ãµes:**
- `skip >= 0`
- `1 <= limit <= 1000`

**Response:** `List[Book]`

---

#### **ğŸ” Buscar Livro por ID**
```http
GET /api/v1/books/{book_id}
```

**ParÃ¢metros de Path:**
- `book_id` (int, obrigatÃ³rio): ID Ãºnico do livro

**Response:** `Book`

**CÃ³digos de Status:**
- `200`: Livro encontrado
- `404`: Livro nÃ£o encontrado

---

#### **ğŸ” Buscar Livros**
```http
GET /api/v1/books/search
```

**ParÃ¢metros de Query:**
- `title` (str, opcional): Busca parcial no tÃ­tulo do livro
- `category` (str, opcional): Nome exato da categoria
- `skip` (int, opcional): PaginaÃ§Ã£o (padrÃ£o: 0)
- `limit` (int, opcional): Limite de resultados (padrÃ£o: 100)

**ValidaÃ§Ãµes:**
- Pelo menos um parÃ¢metro (`title` ou `category`) Ã© obrigatÃ³rio
- Busca por tÃ­tulo Ã© case-insensitive
- Busca por categoria Ã© case-sensitive e exata

**Response:** `List[Book]`

---

#### **ğŸ“‚ Listar Categorias**
```http
GET /api/v1/categories
```

**Response:** `List[str]`
```json
[
  "Travel",
  "Mystery",
  "Poetry",
  "Fiction",
  "..."
]
```

---

#### **ğŸ’° Filtrar por Faixa de PreÃ§o**
```http
GET /api/v1/books/price-range
```

**ParÃ¢metros de Query:**
- `min_price` (float, opcional): PreÃ§o mÃ­nimo (>= 0)
- `max_price` (float, opcional): PreÃ§o mÃ¡ximo (>= 0)
- `skip` (int, opcional): PaginaÃ§Ã£o (padrÃ£o: 0)
- `limit` (int, opcional): Limite de resultados (padrÃ£o: 100)

**ValidaÃ§Ãµes:**
- Se ambos informados: `min_price <= max_price`
- PreÃ§os devem ser >= 0

**Response:** `List[Book]`

---

#### **â­ Top Livros Mais Bem Avaliados**
```http
GET /api/v1/books/top-rated
```

**ParÃ¢metros de Query:**
- `limit` (int, opcional): NÃºmero de livros a retornar (padrÃ£o: 20, mÃ¡x: 100)

**OrdenaÃ§Ã£o:** Rating (Five â†’ Four â†’ Three â†’ Two â†’ One), depois por tÃ­tulo

**Response:** `List[Book]`

### ğŸ“Š Endpoints de EstatÃ­sticas

#### **ğŸ“ˆ EstatÃ­sticas Gerais**
```http
GET /api/v1/stats/overview
```

**Response:** `StatsOverview`

Retorna contagem total de livros, preÃ§o mÃ©dio, distribuiÃ§Ã£o de ratings e nÃºmero de categorias.

---

#### **ğŸ“Š EstatÃ­sticas por Categoria**
```http
GET /api/v1/stats/categories
```

**Response:** `List[CategoryStats]`

Para cada categoria: contagem de livros, preÃ§o mÃ©dio, preÃ§o mÃ­nimo e mÃ¡ximo.

### ğŸ”§ Endpoints de Monitoramento

#### **â¤ï¸ Health Check Completo**
```http
GET /api/v1/health
```

**Response:** `HealthCheck`

Verifica conectividade com banco de dados e integridade dos dados.

---

#### **âš¡ Status RÃ¡pido**
```http
GET /api/v1/status
```

**Response:**
```json
{
  "status": "ok",
  "message": "API is running"
}
```

Endpoint ultra-rÃ¡pido para verificaÃ§Ã£o bÃ¡sica.

---

#### **ğŸ’¾ Status dos Dados**
```http
GET /api/v1/data-status
```

**Response:**
```json
{
  "has_data": true,
  "status": "data_loaded"
}
```

VerificaÃ§Ã£o especÃ­fica da existÃªncia de dados no banco.

### ğŸš« CÃ³digos de Erro

| CÃ³digo | DescriÃ§Ã£o | Exemplo |
|--------|-----------|---------|
| **400** | Bad Request | ParÃ¢metros invÃ¡lidos |
| **404** | Not Found | Livro nÃ£o encontrado |
| **422** | Unprocessable Entity | Dados de entrada invÃ¡lidos |
| **500** | Internal Server Error | Erro interno do servidor |

### ğŸ”’ Headers de Response

Todos os endpoints retornam:
```http
Content-Type: application/json
```

### ğŸ“ ObservaÃ§Ãµes Importantes

1. **PaginaÃ§Ã£o:** Sempre use os parÃ¢metros `skip` e `limit` para navegaÃ§Ã£o eficiente
2. **Performance:** Endpoints de estatÃ­sticas podem ser mais lentos em datasets grandes
3. **Cache:** Resultados sÃ£o calculados em tempo real (sem cache)
4. **Encoding:** Todas as strings utilizam UTF-8
5. **Timestamps:** NÃ£o hÃ¡ campos de data/hora nos dados atuais

## ğŸ§ª Exemplos PrÃ¡ticos de Uso

### ğŸš€ Testando com cURL

#### **1. Verificar Status da API**
```bash
curl -X GET "http://localhost:8000/api/v1/status" \
  -H "accept: application/json"
```

**Response:**
```json
{
  "status": "ok",
  "message": "API is running"
}
```

---

#### **2. Health Check Completo**
```bash
curl -X GET "http://localhost:8000/api/v1/health" \
  -H "accept: application/json"
```

**Response:**
```json
{
  "status": "healthy",
  "database_connected": true,
  "total_books": 1000
}
```

---

#### **3. Listar Primeiros 5 Livros**
```bash
curl -X GET "http://localhost:8000/api/v1/books?skip=0&limit=5" \
  -H "accept: application/json"
```

**Response:**
```json
[
  {
    "id": 1,
    "title": "A Light in the Attic",
    "price": 51.77,
    "rating": "Three",
    "availability": "In stock",
    "category": "Poetry",
    "image_url": "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg",
    "link": "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
  },
  {
    "id": 2,
    "title": "Tipping the Velvet",
    "price": 53.74,
    "rating": "One",
    "availability": "In stock",
    "category": "Historical Fiction",
    "image_url": "http://books.toscrape.com/media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg",
    "link": "http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html"
  }
]
```

---

#### **4. Buscar Livro por ID**
```bash
curl -X GET "http://localhost:8000/api/v1/books/1" \
  -H "accept: application/json"
```

**Response:**
```json
{
  "id": 1,
  "title": "A Light in the Attic",
  "price": 51.77,
  "rating": "Three",
  "availability": "In stock",
  "category": "Poetry",
  "image_url": "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg",
  "link": "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
}
```

---

#### **5. Buscar Livros por TÃ­tulo**
```bash
curl -X GET "http://localhost:8000/api/v1/books/search?title=light&limit=3" \
  -H "accept: application/json"
```

**Response:**
```json
[
  {
    "id": 1,
    "title": "A Light in the Attic",
    "price": 51.77,
    "rating": "Three",
    "availability": "In stock",
    "category": "Poetry",
    "image_url": "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg",
    "link": "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
  }
]
```

---

#### **6. Buscar Livros por Categoria**
```bash
curl -X GET "http://localhost:8000/api/v1/books/search?category=Poetry&limit=2" \
  -H "accept: application/json"
```

**Response:**
```json
[
  {
    "id": 1,
    "title": "A Light in the Attic",
    "price": 51.77,
    "rating": "Three",
    "availability": "In stock",
    "category": "Poetry",
    "image_url": "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg",
    "link": "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
  }
]
```

---

#### **7. Listar Todas as Categorias**
```bash
curl -X GET "http://localhost:8000/api/v1/categories" \
  -H "accept: application/json"
```

**Response:**
```json
[
  "Travel",
  "Mystery",
  "Historical Fiction",
  "Sequential Art",
  "Classics",
  "Philosophy",
  "Romance",
  "Women's Fiction",
  "Fiction",
  "Poetry"
]
```

---

#### **8. Filtrar por Faixa de PreÃ§o**
```bash
curl -X GET "http://localhost:8000/api/v1/books/price-range?min_price=50&max_price=55&limit=3" \
  -H "accept: application/json"
```

**Response:**
```json
[
  {
    "id": 1,
    "title": "A Light in the Attic",
    "price": 51.77,
    "rating": "Three",
    "availability": "In stock",
    "category": "Poetry",
    "image_url": "http://books.toscrape.com/media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg",
    "link": "http://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html"
  },
  {
    "id": 2,
    "title": "Tipping the Velvet",
    "price": 53.74,
    "rating": "One",
    "availability": "In stock",
    "category": "Historical Fiction",
    "image_url": "http://books.toscrape.com/media/cache/26/0c/260c6ae16bce31c8f8c95daddd9f4a1c.jpg",
    "link": "http://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html"
  }
]
```

---

#### **9. Top Livros Mais Bem Avaliados**
```bash
curl -X GET "http://localhost:8000/api/v1/books/top-rated?limit=3" \
  -H "accept: application/json"
```

**Response:**
```json
[
  {
    "id": 5,
    "title": "The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull",
    "price": 17.93,
    "rating": "Five",
    "availability": "In stock",
    "category": "Default",
    "image_url": "http://books.toscrape.com/media/cache/3d/54/3d54940e57e662c4dd1f3ff00c78cc64.jpg",
    "link": "http://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html"
  }
]
```

---

#### **10. EstatÃ­sticas Gerais**
```bash
curl -X GET "http://localhost:8000/api/v1/stats/overview" \
  -H "accept: application/json"
```

**Response:**
```json
{
  "total_books": 1000,
  "average_price": 35.67,
  "rating_distribution": {
    "Five": 213,
    "Four": 213,
    "Three": 200,
    "Two": 190,
    "One": 184
  },
  "categories_count": 50
}
```

---

#### **11. EstatÃ­sticas por Categoria**
```bash
curl -X GET "http://localhost:8000/api/v1/stats/categories" \
  -H "accept: application/json" | head -20
```

**Response (primeiras categorias):**
```json
[
  {
    "category": "Travel",
    "book_count": 11,
    "average_price": 32.15,
    "min_price": 10.99,
    "max_price": 56.50
  },
  {
    "category": "Mystery",
    "book_count": 32,
    "average_price": 28.45,
    "min_price": 12.25,
    "max_price": 58.99
  },
  {
    "category": "Poetry",
    "book_count": 19,
    "average_price": 42.35,
    "min_price": 13.99,
    "max_price": 57.25
  }
]
```

### ğŸ Testando com Python

#### **Exemplo com requests:**
```python
import requests
import json

# Base URL
BASE_URL = "http://localhost:8000/api/v1"

# 1. Health Check
response = requests.get(f"{BASE_URL}/health")
print("Health:", response.json())

# 2. Buscar livros
response = requests.get(f"{BASE_URL}/books", params={"limit": 5})
books = response.json()
print(f"Total livros: {len(books)}")

# 3. Buscar por categoria
response = requests.get(f"{BASE_URL}/books/search", 
                       params={"category": "Poetry", "limit": 3})
poetry_books = response.json()
for book in poetry_books:
    print(f"- {book['title']} (${book['price']})")

# 4. EstatÃ­sticas
response = requests.get(f"{BASE_URL}/stats/overview")
stats = response.json()
print(f"Total de livros: {stats['total_books']}")
print(f"PreÃ§o mÃ©dio: ${stats['average_price']:.2f}")
```

### ğŸ§ª Script de Testes Automatizados

Execute o script de testes para verificar todos os endpoints:

```bash
python test_api.py
```

**SaÃ­da esperada:**
```
ğŸ§ª Testing Book Recommender API
===============================
âœ… API Status: OK
âœ… Health Check: healthy
âœ… Books listing: 100 books found
âœ… Book by ID: Found book with ID 1
âœ… Search by title: Found books matching 'light'
âœ… Search by category: Found books in 'Poetry'
âœ… Categories: 50 categories found
âœ… Price range: Found books between $20-$30
âœ… Top rated: Found top 10 rated books
âœ… Stats overview: Retrieved general statistics
âœ… Category stats: Retrieved stats for all categories
===============================
âœ… All tests passed!
```

## ğŸ“Š Estrutura dos Dados

### ğŸ—ï¸ Modelo de Dados (Book)

| Campo | Tipo | DescriÃ§Ã£o | Exemplo |
|-------|------|-----------|---------|
| **id** | Integer | Identificador Ãºnico (chave primÃ¡ria) | `1` |
| **title** | String | Nome completo do livro | `"A Light in the Attic"` |
| **price** | Float | PreÃ§o em libras esterlinas | `51.77` |
| **rating** | String | AvaliaÃ§Ã£o textual (One a Five) | `"Three"` |
| **availability** | String | Status de disponibilidade | `"In stock"` |
| **category** | String | Categoria/gÃªnero do livro | `"Poetry"` |
| **image_url** | Text | URL da capa do livro | `"http://books.toscrape.com/media/..."` |
| **link** | Text | URL da pÃ¡gina do livro | `"http://books.toscrape.com/catalogue/..."` |

### ğŸ’¾ Estrutura do Banco de Dados

O projeto utiliza **SQLite** como banco local com Ã­ndices otimizados:

```sql
CREATE TABLE books (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    title VARCHAR NOT NULL,
    price FLOAT,
    rating VARCHAR,
    availability VARCHAR,
    category VARCHAR,
    image_url TEXT,
    link TEXT
);

-- Ãndices para performance
CREATE INDEX idx_books_price ON books(price);
CREATE INDEX idx_books_rating ON books(rating);
CREATE INDEX idx_books_category ON books(category);
CREATE INDEX idx_books_title ON books(title);
```

### ğŸ“ˆ Pipeline de Dados ETL

```mermaid
graph LR
    A[Books to Scrape] --> B[Web Scraper]
    B --> C[Raw HTML]
    C --> D[BeautifulSoup Parser]
    D --> E[Data Cleaning]
    E --> F[CSV Export]
    F --> G[SQLite Database]
    G --> H[FastAPI]
    H --> I[JSON Response]
```

**Etapas detalhadas:**

1. **ğŸ•·ï¸ ExtraÃ§Ã£o (scrape_books.py)**
   - NavegaÃ§Ã£o automatizada por todas as pÃ¡ginas
   - Parsing HTML com BeautifulSoup4
   - ExtraÃ§Ã£o de metadados estruturados

2. **ğŸ”„ TransformaÃ§Ã£o**
   - Limpeza de caracteres especiais
   - ConversÃ£o de preÃ§os (string â†’ float)
   - NormalizaÃ§Ã£o de categorias
   - ValidaÃ§Ã£o de URLs

3. **ğŸ’¾ Carregamento (csv_to_db.py)**
   - CriaÃ§Ã£o automÃ¡tica de tabelas
   - InserÃ§Ã£o em lote para performance
   - CriaÃ§Ã£o de Ã­ndices otimizados
   - ValidaÃ§Ã£o de integridade

4. **ğŸš€ DisponibilizaÃ§Ã£o (FastAPI)**
   - Endpoints RESTful
   - ValidaÃ§Ã£o com Pydantic
   - DocumentaÃ§Ã£o automÃ¡tica
   - Tratamento de erros

## ğŸ¯ Casos de Uso e AplicaÃ§Ãµes

### ğŸ¤– Machine Learning
- **Sistema de RecomendaÃ§Ã£o:** Features categÃ³ricas e numÃ©ricas prontas
- **AnÃ¡lise de Sentimento:** Dados textuais dos tÃ­tulos
- **Clustering:** Agrupamento por preÃ§o/categoria/rating
- **PrevisÃ£o de PreÃ§os:** RegressÃ£o baseada em features

### ğŸ“Š Analytics e BI
- **Dashboards:** DistribuiÃ§Ã£o de preÃ§os e ratings
- **RelatÃ³rios:** Performance por categoria
- **AnÃ¡lise de Mercado:** TendÃªncias de preÃ§os
- **KPIs:** MÃ©tricas de catÃ¡logo

### ğŸ›’ E-commerce
- **CatÃ¡logo de Produtos:** Base para loja virtual
- **Sistema de Busca:** Filtros avanÃ§ados
- **RecomendaÃ§Ãµes:** "Livros similares"
- **GestÃ£o de InventÃ¡rio:** Status de disponibilidade

## ğŸ› ï¸ Stack TecnolÃ³gico

### **Backend Core**
```yaml
Linguagem: Python 3.8+
Framework: FastAPI 0.116.0
Servidor: Uvicorn (ASGI)
ORM: SQLAlchemy 2.0.36
Banco: SQLite (local/desenvolvimento)
```

### **Data Pipeline**
```yaml
Web Scraping: BeautifulSoup4 + Requests
Processamento: Pandas 2.2.2
ValidaÃ§Ã£o: Pydantic (schemas)
SerializaÃ§Ã£o: JSON nativo
```

### **Infraestrutura**
```yaml
ContainerizaÃ§Ã£o: Docker + Docker Compose
Servidor ProduÃ§Ã£o: Gunicorn + Uvicorn Workers
Monitoramento: Health checks nativos
Logs: Python logging + Uvicorn logs
```

### **DependÃªncias Principais**
```python
# requirements.txt detalhado
requests==2.32.3        # HTTP client para scraping
beautifulsoup4==4.12.3  # HTML parsing
pandas==2.2.2           # Data manipulation
fastapi==0.116.0        # Web framework moderno
uvicorn[standard]==0.35.0  # ASGI server
python-dotenv==1.1.1    # Environment variables
sqlalchemy==2.0.36      # SQL toolkit e ORM
gunicorn==21.2.0        # WSGI server para produÃ§Ã£o
psutil==5.9.8           # System monitoring
```

## ğŸš€ Roadmap de Desenvolvimento

### **Fase 1: Base (ConcluÃ­da) âœ…**
- [x] Web scraping automatizado
- [x] Pipeline ETL completo
- [x] API RESTful funcional
- [x] DocumentaÃ§Ã£o interativa
- [x] ContainerizaÃ§Ã£o Docker

### **Fase 2: ProduÃ§Ã£o (Em Planejamento) ğŸ“‹**
- [ ] Deploy em cloud (Render/Railway)
- [ ] AutenticaÃ§Ã£o JWT
- [ ] Rate limiting
- [ ] Logging estruturado
- [ ] Monitoramento de performance

### **Fase 3: ML Ready (Futuro) ğŸ”®**
- [ ] Endpoints especÃ­ficos para ML
- [ ] Feature store
- [ ] Pipeline de treinamento
- [ ] Modelo de recomendaÃ§Ã£o
- [ ] A/B testing framework

### **Fase 4: Escala (VisÃ£o) ğŸ¯**
- [ ] Cache distribuÃ­do (Redis)
- [ ] Banco de produÃ§Ã£o (PostgreSQL)
- [ ] MicroserviÃ§os
- [ ] Analytics em tempo real
- [ ] Dashboard de mÃ©tricas

## ğŸ”§ Troubleshooting

### **Problemas Comuns e SoluÃ§Ãµes**

#### **âŒ Erro: "Module not found"**
```bash
# SoluÃ§Ã£o: Ativar ambiente virtual
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Reinstalar dependÃªncias
pip install -r requirements.txt
```

#### **âŒ Erro: "Database not found"**
```bash
# SoluÃ§Ã£o: Recriar base de dados
mkdir -p data
python scripts/csv_to_db.py
```

#### **âŒ Erro: "Port already in use"**
```bash
# SoluÃ§Ã£o: Usar porta diferente
python main.py --port 8001

# Ou matar processo que usa a porta
lsof -ti:8000 | xargs kill -9
```

#### **âŒ Erro: "No data scraped"**
```bash
# SoluÃ§Ã£o: Verificar conectividade e re-executar
curl -I https://books.toscrape.com/
python scripts/scrape_books.py
```

### **ğŸ” Logs e Debug**
```bash
# Logs detalhados
uvicorn main:app --log-level debug

# Verificar status dos dados
curl http://localhost:8000/api/v1/data-status

# Teste rÃ¡pido de conectividade
python -c "import requests; print(requests.get('http://localhost:8000/api/v1/status').json())"
```

## ğŸ¤ ContribuiÃ§Ã£o

### **Como Contribuir**
1. FaÃ§a fork do projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### **Reportar Bugs**
- Use as [GitHub Issues](https://github.com/seu-usuario/book-recommender-api-pipeline/issues)
- Inclua logs relevantes
- Descreva passos para reproduzir o problema

## ğŸ“ LicenÃ§a

Este projeto foi desenvolvido para fins **educacionais** como parte do **Tech Challenge da PÃ³s-Tech**.

### **Uso Educacional**
- âœ… Estudo pessoal
- âœ… ReferÃªncia para projetos acadÃªmicos
- âœ… Base para expansÃ£o e melhorias
- âœ… Portfolio profissional

### **LimitaÃ§Ãµes**
- âš ï¸ NÃ£o usar para fins comerciais sem autorizaÃ§Ã£o
- âš ï¸ Dados do Books to Scrape sujeitos aos termos do site
- âš ï¸ API destinada a demonstraÃ§Ã£o e aprendizado

---

## ğŸ‘¨â€ğŸ’» Sobre o Projeto

**Desenvolvido por:** Equipe Tech Challenge  
**Curso:** PÃ³s-Tech | Machine Learning Engineering - Fase 1  
**InstituiÃ§Ã£o:** [Sua InstituiÃ§Ã£o]  
**Data:** 2024  

### **Objetivos AcadÃªmicos Atingidos:**
- [x] Pipeline ETL completo
- [x] API RESTful robusta
- [x] DocumentaÃ§Ã£o profissional
- [x] ContainerizaÃ§Ã£o
- [x] PrÃ¡ticas de desenvolvimento

### **Tecnologias Demonstradas:**
- [x] Python avanÃ§ado
- [x] FastAPI moderno
- [x] Web scraping Ã©tico
- [x] Banco de dados relacional
- [x] Docker e containerizaÃ§Ã£o

---

## ğŸ“š DocumentaÃ§Ã£o Completa

| Documento | DescriÃ§Ã£o | ConteÃºdo |
|-----------|-----------|----------|
| **[README.md](./README.md)** | DocumentaÃ§Ã£o principal | InstalaÃ§Ã£o, configuraÃ§Ã£o, API, exemplos |
| **[PIPELINE.md](./PIPELINE.md)** | Pipeline de dados detalhado | Arquitetura, diagramas, mÃ©tricas, fluxos |
| **[DEPLOY.md](./DEPLOY.md)** | InstruÃ§Ãµes de deploy | ProduÃ§Ã£o, cloud, configuraÃ§Ãµes |
| **[DOCKER_DEPLOY.md](./DOCKER_DEPLOY.md)** | Deploy com containers | Docker, Kubernetes, orquestraÃ§Ã£o |

### ğŸ”— Links RÃ¡pidos
- ğŸš€ [InÃ­cio RÃ¡pido](#-setup-automÃ¡tico-recomendado)
- ğŸ—ï¸ [Arquitetura](./PIPELINE.md#-arquitetura-geral-do-sistema)
- ğŸ“š [DocumentaÃ§Ã£o da API](#-documentaÃ§Ã£o-completa-da-api)
- ğŸ§ª [Exemplos de Uso](#-exemplos-prÃ¡ticos-de-uso)
- ğŸ³ [Deploy Docker](./DOCKER_DEPLOY.md)
- ğŸ”§ [Troubleshooting](#-troubleshooting)